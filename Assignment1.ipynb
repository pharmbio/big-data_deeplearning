{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assingment 1\n",
    "*by Ebba Bergman*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something very similar to the lab\n",
    "\n",
    "**Hand in:**This notebook, and a pdf of this notebook. No written answers to the questions are required, they are only here to help you learn\n",
    "\n",
    "**You are free to discuss the general concepts with other groups, but we encourage you not to exchange code for your own learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the code below is inspired labs developed by Christophe Avenel at NBIS , labs and assignments made by Phil Harrison as well as  by https://www.tensorflow.org/guide/keras/functional/,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we need to import all of the packages we need\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import IPython\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import cnn_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the cnn_helper was written by Christophe Avenel, and his code (including his lab which this one is based on), is available here: https://github.com/NBISweden/workshop-neural-nets-and-deep-learning/tree/master/session_convolutionalNeuralNetworks/Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def plot_history(model_history, model_name):\n",
    "    fig = plt.figure(figsize=(15, 5), facecolor='w')\n",
    "    ax = fig.add_subplot(131)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['train', 'valid'], loc='upper right')\n",
    "    \n",
    "    ax = fig.add_subplot(132)\n",
    "    ax.plot(np.log(model_history.history['loss']))\n",
    "    ax.plot(np.log(model_history.history['val_loss']))\n",
    "    ax.set(title=model_name + ': Log model loss', ylabel='Log loss', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Test'], loc='upper right')    \n",
    "\n",
    "    ax = fig.add_subplot(133)\n",
    "    ax.plot(model_history.history['accuracy'])\n",
    "    ax.plot(model_history.history['val_accuracy'])\n",
    "    ax.set(title=model_name + ': Model accuracy', ylabel='Accuracy', xlabel='Epoch')\n",
    "    ax.legend(['train', 'valid'], loc='upper right')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.savefig(\"History Plot.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the data, look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up where to find our data\n",
    "data_directory = \"./LabData/bloodcells_small/data/\"\n",
    "labels_path =  \"./LabData/bloodcells_small/labels.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a dataframe, a way to look at data as tables.\n",
    "#Google \"Python pandas dataframe\" to get more information, or to find new commands as you need\n",
    "# Anything you can do with data frames you could do with loops, but it is sometimes easier to read and write code with dataframes\n",
    "df_labels = pd.read_csv(labels_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Look at the labels, what columns do you think contains the true label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's look at the images - always a good start to the project\n",
    "# Here random images will be displayed, run this several time to see different images\n",
    "\n",
    "figure, ax = plt.subplots(2, 3, figsize=(14, 10))\n",
    "figure.suptitle(\"Examples of images\", fontsize=20)\n",
    "axes = ax.ravel()\n",
    "\n",
    "df_images_to_show = df_labels.sample(8)\n",
    "\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    row = df_images_to_show.iloc[[i]]\n",
    "    random_image = Image.open(data_directory + row[\"Filenames\"].values[0])\n",
    "    axes[i].set_title(row[\"Class\"].values[0], fontsize=14) \n",
    "    axes[i].imshow(random_image)\n",
    "    axes[i].set_axis_off()\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Can you see any difference between the classes? \n",
    "### Q: Do you think a human being able to see the difference between classes makes it an easier or more difficult problem for a neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the shape of the image?\n",
    "image_shape = np.array(random_image).shape\n",
    "print(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look a little bit into the labels\n",
    "set_size = df_labels.size\n",
    "print(set_size)\n",
    "print(df_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the data for training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next, let's divide the filtered rows into a train, validation and a test set. \n",
    "class_column_header = \"Class\"\n",
    "df_to_use = df_labels.copy() #We're copying the df_labels so that you can look at it again later if you want\n",
    "\n",
    "test_set_fraction = 0.1\n",
    "validation_set_fraction = 0.2\n",
    "\n",
    "df_test = df_to_use.groupby(class_column_header).sample(frac = test_set_fraction)\n",
    "df_to_use = pd.concat([df_to_use, df_test, df_test]).drop_duplicates(keep=False) # This line finds the intersection between df_filtered and df_test and df_test and dropps anything that belongs to two of those, so we are left with df_train. Using only df_test once should be fine, but better safe than sorry\n",
    "df_valid = df_to_use.groupby(class_column_header).sample(frac = validation_set_fraction)\n",
    "df_train = pd.concat([df_to_use, df_valid, df_valid]).drop_duplicates(keep=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up generators that specify how the images are loaded, how many at a time (batch size),\n",
    "## that the images should be shuffled should be shuffled etc.\n",
    "batch_size = 8\n",
    "\n",
    "filename_column = 'Filenames'\n",
    "true_value = \"Class\"\n",
    "# create a data generator\n",
    "\n",
    "## Note: we tend to get better results if the values of the pixels are between 0 and 1, so we need a rescale of 1/255 since the highest possible pixel value for these images are 255\n",
    "train_data_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, samplewise_center=True, samplewise_std_normalization=True)\n",
    "valid_data_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, samplewise_center=True, samplewise_std_normalization=True)\n",
    "test_data_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, samplewise_center=True, samplewise_std_normalization=True)\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(\n",
    "    df_train, directory=data_directory, x_col=filename_column, y_col=true_value,\n",
    "    weight_col=None, class_mode='categorical', batch_size=batch_size, target_size = image_shape,  color_mode='grayscale' ,shuffle=True,\n",
    ")\n",
    "\n",
    "valid_generator = valid_data_generator.flow_from_dataframe(\n",
    "    df_valid, directory=data_directory, x_col=filename_column, y_col=true_value,\n",
    "    weight_col=None, class_mode='categorical', batch_size=batch_size, target_size = image_shape,  color_mode='grayscale' , shuffle=False,\n",
    ")\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(\n",
    "    df_test, directory=data_directory, x_col=filename_column, y_col=true_value,\n",
    "    weight_col=None,class_mode='categorical', batch_size=batch_size, target_size = image_shape,  color_mode='grayscale' , shuffle=False,\n",
    ")\n",
    "\n",
    "\n",
    "train_steps=train_generator.n//train_generator.batch_size if train_generator.n >= train_generator.batch_size else 1\n",
    "validation_steps=valid_generator.n//valid_generator.batch_size if valid_generator.n >= valid_generator.batch_size else 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks revolutionized the field of deep learning. You have seen how convolutions work in the lectures. One of the huge benefits of convolutions is that as the filters (sometimes called kernels in codes) move across the image the position of an object in an image becomes much less important than when we flattened images to use in traditional Artificial Neural Networks. \n",
    "  \n",
    "For this part of the lab you will try a couple of different architectures and hyperparameters. The **architecture** is basically the structure of the network: how many nodes, how many layers, and overall shape of these. The **hyperparamters** are most easily defined as all of the parameters changed *before* the training of the network begin, such as the number of epochs, what activation function to use in each layer, and which optimization method we use for backpropagation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the model architecture\n",
    "# See https://www.tensorflow.org/guide/keras/functional/ if you want to see the documentation\n",
    "\n",
    "cnn_inputs = keras.Input(shape=(32,32,1))\n",
    "x = layers.Conv2D(1, kernel_size=(3, 3), strides=1,padding='same')(cnn_inputs)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "cnn_outputs = layers.Dense(5, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the model as a keras model\n",
    "cnn_model = keras.Model(inputs=cnn_inputs, outputs=cnn_outputs, name=\"cnn_Model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We'll use the same generators as above here, so no need to redefine them\n",
    "## compile model\n",
    "\n",
    "cnn_model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actually train model\n",
    "epochs = 5\n",
    "history = cnn_model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch= train_steps,\n",
    "                    validation_data= valid_generator,\n",
    "                    validation_steps= validation_steps,\n",
    "                    epochs= epochs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot results\n",
    "plot_history(history, \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "cnn_helper.plot_confusion_matrix_from_generator(cnn_model, valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What do the curves tell you about the models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see some examples of how curves can look at : https://uppsala.instructure.com/courses/23804/pages/deep-learning-plots/edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a deeper model and/or a more complex model, can be helpful. Try adding some more convolution layers and pooling layers to the model. Try changing the filter sizes, and the number of filters as well.\n",
    "More information about the convolutional layer can be found here: https://keras.io/api/layers/convolution_layers/convolution2d/, maxpooling here: https://keras.io/api/layers/pooling_layers/max_pooling2d/, and a different kind of way of making models can be found here: https://www.tensorflow.org/tutorials/images/cnn  and here https://www.tensorflow.org/tutorials/quickstart/advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the model architecture\n",
    "\n",
    "#Change the code below so that the new model has roughly the same number of parameters as your best ANN\n",
    "# Hint: you can add both more Conc2D layers, and increase the kernel (filter) size\n",
    "\n",
    "cnn_inputs = keras.Input(shape=(32,32,1))\n",
    "x = layers.Conv2D(5, kernel_size=(3, 3), strides=1,padding='same')(cnn_inputs)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "cnn_outputs = layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "## Define the model \n",
    "cnn_model = keras.Model(inputs=cnn_inputs, outputs=cnn_outputs, name=\"cnn_Model_2\")\n",
    "\n",
    "## Compile the model\n",
    "cnn_model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actually train model\n",
    "epochs = 10\n",
    "history = cnn_model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch= train_steps,\n",
    "                    validation_data= valid_generator,\n",
    "                    validation_steps= validation_steps,\n",
    "                    epochs= epochs\n",
    "                                 )         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot results\n",
    "plot_history(history, \"cnn_model\")\n",
    "\n",
    "# plot confusion matrix\n",
    "cnn_helper.plot_confusion_matrix_from_generator(cnn_model, valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a couple of deeper models and save your best one for further study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add all these models beneath this heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's try something else, maybe you would like to add some data augmentation? \n",
    "Data augmentation basically means that we randomly alter the incoming images in different ways to make sure that the network can handle those types of variations.\n",
    "\n",
    "If you want to read more you can look at this article, especially the \"Data Augmentations based on basic image manipulations Geometric transformations\" is of interest here: https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0\n",
    "\n",
    "See https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator for things you can try by adding input paramters to the ImageDataGenerator().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the cell below to  **include data augmentations, only in the training data generator then run your CNN again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up generators \n",
    "batch_size = 8\n",
    "\n",
    "filename_column = 'Filenames'\n",
    "true_value = \"Class\"\n",
    "# create a data generator\n",
    "\n",
    "## Note: we tend to get better results if the values of the pixels are between 0 and 1, so we need a rescale of 1/255 since the highest possible pixel value for these images are 255\n",
    "train_data_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, samplewise_center=True, samplewise_std_normalization=True ,## ADD CODE HERE)\n",
    "valid_data_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, samplewise_center=True, samplewise_std_normalization=True)\n",
    "test_data_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, samplewise_center=True, samplewise_std_normalization=True)\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(\n",
    "    df_train, directory=data_directory, x_col=filename_column, y_col=true_value,\n",
    "    weight_col=None, class_mode='categorical', batch_size=batch_size, target_size = image_shape,  color_mode='grayscale' ,shuffle=True,\n",
    ")\n",
    "\n",
    "valid_generator = valid_data_generator.flow_from_dataframe(\n",
    "    df_valid, directory=data_directory, x_col=filename_column, y_col=true_value,\n",
    "    weight_col=None, class_mode='categorical', batch_size=batch_size, target_size = image_shape,  color_mode='grayscale' , shuffle=False,\n",
    ")\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(\n",
    "    df_test, directory=data_directory, x_col=filename_column, y_col=true_value,\n",
    "    weight_col=None,class_mode='categorical', batch_size=batch_size, target_size = image_shape,  color_mode='grayscale' , shuffle=False,\n",
    ")\n",
    "\n",
    "\n",
    "train_steps=train_generator.n//train_generator.batch_size if train_generator.n >= train_generator.batch_size else 1\n",
    "validation_steps=valid_generator.n//valid_generator.batch_size if valid_generator.n >= valid_generator.batch_size else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the model architecture\n",
    "### use your best model from above, and rename it here to cnn_model_augmented\n",
    "cnn_inputs = keras.Input(shape=(32,32,1))\n",
    "x = layers.Conv2D(1, kernel_size=(3, 3), strides=2,padding='same')(cnn_inputs)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "cnn_outputs = layers.Dense(5, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the model \n",
    "cnn_model = keras.Model(inputs=cnn_inputs, outputs=cnn_outputs, name=\"cnn_Model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile the model\n",
    "\n",
    "cnn_model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actually train model\n",
    "epochs = 10\n",
    "history = cnn_model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch= train_steps,\n",
    "                    validation_data= valid_generator,\n",
    "                    validation_steps= validation_steps,\n",
    "                    epochs= epochs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot results\n",
    "plot_history(history, \"Data Augmentation added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "cnn_helper.plot_confusion_matrix_from_generator(cnn_model, valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Did the data augmentation help? Why or why not? What makes this dataset more or less likely to be helped by data augmentation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"green\">\n",
    "<b>Optional hints for <code><font size=\"4\">question above</font></code></b>\n",
    "</font>\n",
    "</summary>\n",
    "    1. Are the blood cells at random places in the image?\n",
    "    \n",
    "2. Look at some of the images. Are the bloodcells centered? What could rotations or zooms change about this?\n",
    "    \n",
    "3. Are there color changes you could compensate for?    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularisation methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both BatchNormalization and DropOut are two different regularisation methods. Try adding both to the best working CNN model.  \n",
    "  \n",
    "Read more about BatchNormalization here: https://keras.io/api/layers/normalization_layers/batch_normalization/\n",
    "Read more about DropOut here:https://keras.io/api/layers/regularization_layers/dropout/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q:  What are the main similarities and differences between these methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the model here\n",
    "## Set up the model architecture\n",
    "### use your best model from above\n",
    "\n",
    "cnn_inputs = keras.Input(shape=(32,32,1))\n",
    "x = layers.Conv2D(1, kernel_size=(3, 3), strides=2,padding='same')(cnn_inputs)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "cnn_outputs = layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the model \n",
    "cnn_model = keras.Model(inputs=cnn_inputs, outputs=cnn_outputs, name=\"cnn_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile the model\n",
    "\n",
    "cnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actually train model\n",
    "epochs = 15\n",
    "history = cnn_model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch= train_steps,\n",
    "                    validation_data= valid_generator,\n",
    "                    validation_steps= validation_steps,\n",
    "                    epochs= epochs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot results\n",
    "plot_history(history, \"test_Name\")\n",
    "\n",
    "# plot confusion matrix\n",
    "cnn_helper.plot_confusion_matrix_from_generator(cnn_model, valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Is there such a thing as too much regularisation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise your best CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to visualise some of the weights you have trained. Hint: Weights are present in convolutional filters and dense layers, nowhere else.\n",
    "### Visualize both one layer with filters, and the outputlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the layer \n",
    "print(cnn_model.layers)\n",
    "cw1 = np.array(cnn_model.layers[1].get_weights()) ## Pick the layer whose weights you want to visualise\n",
    "print(cw1.shape) # 2 weight, 1 weight, 1 bias\n",
    "print(cw1[0].shape) # Weights\n",
    "print(cw1[1].shape) # Biases\n",
    "matrix = cw1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your filters \n",
    "figure, ax = plt.subplots(2, 3, figsize=(14, 10))\n",
    "figure.suptitle(\"Weights visualized\", fontsize=20)\n",
    "axes = ax.ravel()\n",
    "\n",
    "for i in range(0,1): # Range should be 0 - the number of filters you have\n",
    "    image = matrix[:,:,i:i+1]\n",
    "    image = np.reshape(matrix, (2, 2)) ## Reshape to the size of your filters\n",
    "    axes[i].set_title(\"Filter\" + str(i+1), fontsize=14) \n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_axis_off()\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using existing models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One great thing to do when making a CNN model is to use an architecture that has worked for simmilar cases. I happen to know that the existing CNN model VGG16 is a good model for these types of images, try that one next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many way of visualising neural networks, see https://datascience.stackexchange.com/questions/12851/how-do-you-visualize-neural-network-architectures, but here is one made by Christophe Avenel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Illustrations/vgg16.png\" title=\"VGG16 model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_shape=(32, 32, 1),\n",
    "    pooling=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add new classifier layers\n",
    "flat1 = layers.Flatten()(vgg_model.layers[-1].output)\n",
    "class1 = layers.Dense(1024, activation='relu')(flat1)\n",
    "output = layers.Dense(5, activation='softmax')(class1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg_model = keras.Model(inputs=vgg_model.inputs, outputs=output)\n",
    "\n",
    "print (vgg_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: How many parameters does this model have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile the model\n",
    "\n",
    "vgg_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Why do we need a new classification layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"green\">\n",
    "<b>Optional hints for <code><font size=\"4\">question above</font></code></b>\n",
    "</font>\n",
    "</summary>\n",
    "1. What is the original network classifying? \n",
    "\n",
    "2. What do we want to classify? \n",
    "    \n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"green\">\n",
    "<b>Optional hints for <code><font size=\"4\">The hint, if you need it</font></code></b>\n",
    "</font>\n",
    "</summary>\n",
    "1. So how do we remove the previous classification and make the new one? Just like the code above naturally! A flattening layer is almost always followed by a dense layer or two to expand the model, and then a final classification layer.\n",
    "    \n",
    "\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actually train model\n",
    "epochs = 10\n",
    "history = vgg_model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch= train_steps,\n",
    "                    validation_data= valid_generator,\n",
    "                    validation_steps= validation_steps,\n",
    "                    epochs= epochs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot results\n",
    "plot_history(history, \"VGG16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "cnn_helper.plot_confusion_matrix_from_generator(vgg_model, valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What is your worst performing class in this classifier? Is it the same as in the other ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: How many layers with 10 filters of size 3*3 would you have to add to the first CNN model we designed to achieve the same number of parameters?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try some more models.\n",
    "\n",
    "Try other optimizers, learning rates, batch sizes or number of epochs. Which would you like to try first and why? Show atleast 4 models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally test your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps=test_generator.n//test_generator.batch_size if test_generator.n >= test_generator.batch_size else 1\n",
    "\n",
    "pred=unknown_model.predict_generator(test_generator, ## replace unknown_model with your best model\n",
    "steps=test_steps,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_helper.plot_confusion_matrix_from_generator(unknown_model, test_generator) ## replace unknown_model with your best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN \n",
    "\n",
    "Make a neural network without any convolutions that achieves atleast 90% on the validation test. It will be possible with the techniques you have used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the model architecture\n",
    "inputs = keras.Input(shape= (32,32,1))\n",
    "#Extend your model here (atleast)\n",
    "outputs = layers.Dense(5, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional\n",
    "\n",
    "Try using different proportions for training, validation and test. How does this affect your results? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
