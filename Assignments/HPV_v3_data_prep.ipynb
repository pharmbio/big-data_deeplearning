{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Teaching/BigDataDL/Assignments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1229"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tifffile import imwrite\n",
    "\n",
    "# Function to ensure each directory gets at least one image\n",
    "def ensure_initial_images(assigned, directory, index, im_new):\n",
    "    if not assigned:\n",
    "        imwrite(directory + '/' + f'cell_{index}.tif', im_new)\n",
    "        return True, index + 1\n",
    "    return assigned, index\n",
    "\n",
    "# Process slides with modified directory assignment\n",
    "def process_slides(slides, type_dir, initial_assigned):\n",
    "    index = 1  # Start indexing for cell images\n",
    "    assigned = {key: False for key in initial_assigned}\n",
    "\n",
    "    for slide in slides:\n",
    "        with h5py.File(original_dir + slide + '.hdf5', 'r') as f:\n",
    "            dset = f['data']\n",
    "            n_cells = dset.shape[0]\n",
    "            current_samp_size = min(samp_size, n_cells)  # Adjust sample size based on available cells\n",
    "            samp = np.random.choice(n_cells, current_samp_size, replace=False)\n",
    "\n",
    "            for i in samp:\n",
    "                im = dset[i][0, :, :]\n",
    "                crop = im[(center_xy[0] - offset):(center_xy[0] + offset), (center_xy[1] - offset):(center_xy[1] + offset)]\n",
    "                im_new = np.reshape(crop, (xydim, xydim, 1))\n",
    "\n",
    "                # Ensure at least one image in each directory\n",
    "                for key in assigned:\n",
    "                    if not assigned[key]:\n",
    "                        assigned[key], index = ensure_initial_images(assigned[key], key, index, im_new)\n",
    "\n",
    "                # Random assignment after the initial images\n",
    "                if np.random.uniform() <= split_prob:\n",
    "                    if np.random.uniform() <= split_prob:\n",
    "                        dir_path = type_dir['train']\n",
    "                    else:\n",
    "                        dir_path = type_dir['validation']\n",
    "                else:\n",
    "                    dir_path = type_dir['test']\n",
    "\n",
    "                imwrite(dir_path + '/' + f'cell_{index}.tif', im_new)\n",
    "                index += 1\n",
    "\n",
    "    return index\n",
    "\n",
    "# Directory definitions\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "\n",
    "base_directory = \"/home/jovyan/Teaching/BigDataDL/\"\n",
    "base_dir = base_directory + \"LabData/HPV_slides/\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.makedirs(validation_dir, exist_ok=True)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "train_healthy_dir = os.path.join(train_dir, 'healthy')\n",
    "os.makedirs(train_healthy_dir, exist_ok=True)\n",
    "train_tumor_dir = os.path.join(train_dir, 'tumor')\n",
    "os.makedirs(train_tumor_dir, exist_ok=True)\n",
    "\n",
    "validation_healthy_dir = os.path.join(validation_dir, 'healthy')\n",
    "os.makedirs(validation_healthy_dir, exist_ok=True)\n",
    "validation_tumor_dir = os.path.join(validation_dir, 'tumor')\n",
    "os.makedirs(validation_tumor_dir, exist_ok=True)\n",
    "\n",
    "test_healthy_dir = os.path.join(test_dir, 'healthy')\n",
    "os.makedirs(test_healthy_dir, exist_ok=True)\n",
    "test_tumor_dir = os.path.join(test_dir, 'tumor')\n",
    "os.makedirs(test_tumor_dir, exist_ok=True)\n",
    "\n",
    "original_dir = base_directory + 'ZippedLabData/HPV_slides/'\n",
    "\n",
    "samp_size = 333\n",
    "split_prob = 0.8\n",
    "slides_healthy = ['glass3', 'glass4', 'glass5', 'glass6', 'glass7', 'glass8']\n",
    "slides_tumor = ['glass12', 'glass36', 'glass37', 'glass38']\n",
    "\n",
    "im_x, im_y = 80, 80\n",
    "center_xy = [int(im_x/2), int(im_y/2)]\n",
    "offset = 24\n",
    "xydim = offset * 2\n",
    "\n",
    "# Process each slide type\n",
    "type_dirs_healthy = {'train': train_healthy_dir, 'validation': validation_healthy_dir, 'test': test_healthy_dir}\n",
    "type_dirs_tumor = {'train': train_tumor_dir, 'validation': validation_tumor_dir, 'test': test_tumor_dir}\n",
    "\n",
    "initial_assigned_healthy = {k: False for k in type_dirs_healthy.values()}\n",
    "initial_assigned_tumor = {k: False for k in type_dirs_tumor.values()}\n",
    "\n",
    "last_index_healthy = process_slides(slides_healthy, type_dirs_healthy, initial_assigned_healthy)\n",
    "process_slides(slides_tumor, type_dirs_tumor, initial_assigned_tumor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
