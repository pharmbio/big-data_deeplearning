{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assingment 2\n",
    "\n",
    "Let's again do something very similar to the lab\n",
    "\n",
    "**Hand in:**This notebook, and a pdf of this notebook. No written answers to the questions are required, they are only here to help you learn\n",
    "\n",
    "**You are free to discuss the general concepts with other groups, but not code specifics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Concepts introduced in this lab may appear on the exam, in which case there will be general questions. Try therefore to understand what you are doing in the assignment, and why. Teachers will be available during the scheduled times, and you can also ask questions in the discussion forums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The assignment\n",
    "\n",
    "You have access to 6 glass slides of cells from patients with tumors (sick), and 4 slides from healthy patients. If you do not understand what a glass slide is, simply think of it as a collection of images from one patient. \n",
    "\n",
    "Your task is to make as good as model as you can* in order to predict whether a new glass slide contains cells from a tumor or healthy cells, thus aiding in the diagnosis of patients. \n",
    "\n",
    "This dataset is the same dataset as the one in this master thesis, where you can read more about the data  http://uu.diva-portal.org/smash/get/diva2:1119167/FULLTEXT02.pdf, which resulted in this article which is significantly shorter: https://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w1/Wieslander_Deep_Convolutional_Neural_ICCV_2017_paper.pdf. \n",
    "\n",
    "/* Within reason, specific instructions will be given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we need to import all of the packages we need\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import IPython\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import h5py\n",
    "import os, shutil\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tifffile import imsave\n",
    "import cnn_helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def plot_history(model_history, model_name):\n",
    "    fig = plt.figure(figsize=(15, 5), facecolor='w')\n",
    "    ax = fig.add_subplot(131)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['train', 'valid'], loc='upper right')\n",
    "    \n",
    "    ax = fig.add_subplot(132)\n",
    "    ax.plot(np.log(model_history.history['loss']))\n",
    "    ax.plot(np.log(model_history.history['val_loss']))\n",
    "    ax.set(title=model_name + ': Log model loss', ylabel='Log loss', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Test'], loc='upper right')    \n",
    "\n",
    "    ax = fig.add_subplot(133)\n",
    "    ax.plot(model_history.history['accuracy'])\n",
    "    ax.plot(model_history.history['val_accuracy'])\n",
    "    ax.set(title=model_name + ': Model accuracy', ylabel='Accuracy', xlabel='Epoch')\n",
    "    ax.legend(['train', 'valid'], loc='upper right')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, model_name,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    title = model_name + ': Confusion Matrix'\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def valid_evaluate(y_true, y_pred, model_name):\n",
    "    \n",
    "    class_names = ['Aur', 'Ch', 'Eg5', 'PS', 'DR', 'DS']\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure(figsize=(15,5), facecolor='w')\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, model_name=model_name)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print('')\n",
    "    print('classification report for validation data:')\n",
    "    print(classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the data, look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up where to find our data\n",
    "data_directory = \"./LabData/HPV_slides/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The image data \n",
    "The image data comes in a hdf5 format, which means that we have to do some fun things to make this work. You can read more about the data type here https://support.hdfgroup.org/HDF5/whatishdf5.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slides_healthy = ['glass3', 'glass4', 'glass5', 'glass6', 'glass7', 'glass8']\n",
    "slides_tumor = ['glass12', 'glass36', 'glass37', 'glass38']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one slide first to get a feeling for the data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## My code\n",
    "\n",
    "slide = slides_healthy[0]\n",
    "f = h5py.File(data_directory + slide + '.hdf5' , 'r')\n",
    "\n",
    "dset = f['data'][0:2][1:][:][:]\n",
    "print(dset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dset = f['data']\n",
    "print(dset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Let's look at the images - always a good start to the project\n",
    "\n",
    "figure, ax = plt.subplots(2, 3, figsize=(14, 10))\n",
    "figure.suptitle(\"Examples of images\", fontsize=20)\n",
    "axes = ax.ravel()\n",
    "\n",
    "for i in range(0,5):\n",
    "    image = f['data'][i:i+1][:][:][:]\n",
    "    image = image.reshape(80, 80)\n",
    "    axes[i].set_title(\"image\" + str(i)) \n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_axis_off()\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What happens if we crop the images?\n",
    "## You can read more about squeeze at https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html\n",
    "\n",
    "# overall image size\n",
    "im_x = 80\n",
    "im_y = 80\n",
    "\n",
    "center_xy = [int(im_x/2), int(im_y/2)]\n",
    "\n",
    "# offset = 24 -> tile size of 48 x 48 \n",
    "# (divides nicely by two for when max pooling, captures most of all cells, will learn faster than 80 x 80 original images) ## This was a note from someone who has worked with the dataset\n",
    "offset = 24\n",
    "xydim = offset * 2\n",
    "\n",
    "        \n",
    "\n",
    "figure, ax = plt.subplots(2, 3, figsize=(14, 10))\n",
    "figure.suptitle(\"Examples of cropped images\", fontsize=20)\n",
    "axes = ax.ravel()\n",
    "\n",
    "for i in range(0,5):\n",
    "    image = f['data'][i:i+1][:][:][:]\n",
    "    \n",
    "    image = image.reshape(80, 80)\n",
    "    crop = image[(center_xy[0] - offset):(center_xy[0] + offset), (center_xy[1] - offset):(center_xy[1] + offset)]\n",
    "    print(crop.shape)\n",
    "    image_new = crop.reshape(xydim, xydim)\n",
    "    print(image_new.shape)\n",
    "    axes[i].set_title(\"image\" + str(i)) \n",
    "    axes[i].imshow(image_new)\n",
    "    axes[i].set_axis_off()\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into training, validation and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Mix the data so that images from one slide may be in the train, validation *or* the test set, or both or all three. Simply make the selection of images for a set totally random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "for these images it may be easier to use the flow_from_directory command  see https://keras.io/api/preprocessing/image/   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for the train, valid and test generators here. You may add more cells above this one if you like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about transfer learning here: https://keras.io/guides/transfer_learning/\n",
    "Share extra resources in the discussion forums.\n",
    "\n",
    "Transfer learning is a vital part of most deep learning within life sciences, can you think of why? \n",
    "\n",
    "Hint: Understanding the general concepts of why transfer learning is useful may be useful on the exam. Maybe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load a VGG16 model, remove the last layer, and then train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile model\n",
    "## Don't worry about the details here yet\n",
    "ann_model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actually train model\n",
    "## Don't worry about the details here yet\n",
    "\n",
    "epochs = 5\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch= train_steps,\n",
    "                    validation_data= valid_generator,\n",
    "                    validation_steps= validation_steps,\n",
    "                    epochs= epochs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot results\n",
    "plot_history(history, \"test_Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plot_confusion_matrix_from_generator(model, valid_generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Change the code above so that you get atleast an 80% accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Todo: make a transferlearning model using Resnet50 trained on ImageNet. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Is the initial results better or worse than your VGG16 results? Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: vary the model above using atleast 3 different parameters/ architectures. Show the results for each change and then combine every parameter/architecture that improved the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unknown model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick another model to try, and try reaching a percentage higher than your initial VGG16 results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick your best model above, and introduce atleast 3 different data augmentations 1 by 1. Keep the ones that improve the network (if any) for your final test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, pick the best model you have chosen and test it. (so far you have evaluated(validated) your model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: If a clinician requires a 95% accuracy in their models would you recommend the model you have generated? Why or why. not? What would your next steps be to generate a better neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A different dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: In this previous excercise we have mixed the patients all together. What is the main drawback with this type of datamixing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your best model from above, make a test set that includes 2 patients, and where the training and validation do not contain the same patients. In short, make a data division such that you could attempt to evaluate how well your model would behave with a new patient. Do not be supprised if the model is suddenly much less good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: It is likely that this second training of the model will be worse, why? Why is it not guaranteed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
